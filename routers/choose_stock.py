import pandas as pd
from datetime import datetime, timedelta, date
import time
from io import StringIO
from decimal import Decimal
import random
import json
import os
import pathlib

from src.Step0_InstitutionalInvestors import GetInstitutionalInvestorsExchange
from src.Step1_BasicStockInfo import GetBasicStockInfo
from src.Step2_FinDetail import GetFinDetail
from src.Step3_K_ChartFlow import GetPE
from src.Step4_K_Chart import GetTransaction
import src.Step5_ShareholderDistribution as shareholderDistribution
from src.Step6_StockDividendPolicy import GetDividend
from src.Step7_VolumeData import GetVolume
import src.Step8_DirectorSharehold as directorSharehold
import src.Step9_DailyTopVolume as dailyTopVolume
import requests
from fastapi import APIRouter
from typing import Union
from dotenv import load_dotenv

"""
é¸è‚¡æ¢ä»¶ï¼š
ï¼ˆ1ï¼‰è©•ä¼°åƒ¹å€¼æ˜¯å¦è¢«ä½ä¼°ï¼Ÿï¼ˆè‚¡ç¥¨åƒ¹æ ¼ä¸æœƒå¤ªè²´ï¼‰
1. æœ¬ç›Šæ¯”ã€€ã€€ã€€< 15å€
2. ç¾é‡‘æ®–åˆ©ç‡ã€€> 5 %

ï¼ˆ2ï¼‰æœ¬ç›Šæ¯”ä½ä¼°
1. æœ¬ç›Šæ¯”å°æ–¼10
2. å°æ–¼è¿‘äº”å¹´æœ€å°ç´šè·æœ¬ç›Šæ¯”

ï¼ˆ3ï¼‰ç¢ºå®šæœ¬æ¥­åˆ©ç›Šæ˜¯æˆé•·çš„ï¼Œä¸”ç‚ºæœ¬æ¥­è³ºçš„ï¼ˆä¸æ˜¯é æ¥­å¤–æ”¶ç›Šè³ºçš„ï¼Œç²åˆ©ä¸æŒä¹…ï¼‰
1. ç‡Ÿæ”¶ç´¯è¨ˆå¹´å¢ç‡ > 0 %
2. æ¯›åˆ©ç‡ > 0 %
3. ç‡Ÿæ¥­åˆ©ç›Šç‡ > 0 %
4. ç¨…å‰æ·¨åˆ©ç‡ > 0 %
5. ç¨…å¾Œæ·¨åˆ©ç‡ > 0 %
6. æœ¬æ¥­æ”¶ç›Šï¼ˆç‡Ÿæ¥­åˆ©ç›Šç‡ï¼ç¨…å‰æ·¨åˆ©ç‡ï¼‰ > 60 %
7. ROE > 10
"""

router = APIRouter(
    prefix="/choose_stock",
    tags=["choose_stock"],
    responses={404: {"description": "Not found"}},
)

stocks = [
    "1229",
    "1231",
    "1409",
    "1304",
    "1308",
    "1474",
    "1515",
    "1604",
    "2020",
    "2069",
    "2324",
    "2347",
    "2352",
    "2385",
    "2387",
    "2417",
    "2458",
    "2488",
    "2520",
    "2546",
    "2881",
    "3005",
    "3028",
    "3033",
    "3044",
    "3048",
    "3209",
    "3231",
    "3312",
    "3702",
    "3706",
    "6257",
    "8112",
    "8150",
]


@router.get("/operate/{op}")
def Operate(op: int, stockId: Union[str, None] = None):
    # ä¸‰å¤§æ³•äººè²·è³£é‡‘é¡çµ±è¨ˆè¡¨
    if op == 0:
        return GetInstitutionalInvestorsExchange()
        
    # éæ¿¾æ¸…å–®
    if op == 1:
        df = GetBasicStockInfo(True)
        # print(df)

        df.update(df.apply(lambda x: pd.to_numeric(x, errors="coerce")))

        cond1 = df["æ¯›åˆ©ç‡"] > 30
        cond2 = df["ç‡Ÿæ¥­åˆ©ç›Šç‡"] > 30
        cond3 = df["æœ¬ç›Šæ¯”"] < 15
        cond3 = df["è³‡æœ¬é¡"] > 15
        df = df[cond1 & cond2 & cond3]
        # print(df)

        tableName = "éæ¿¾æ¸…å–®"
        # æ¸…é™¤æ‰€æœ‰è³‡æ–™
        deleteAll(tableName)

        # é‡æ–°å¯«å…¥
        save(tableName, df)
        return {"message": "åŸ·è¡ŒæˆåŠŸ"}

    # æ˜ç´°è³‡æ–™
    if op == 2:
        basicStockInfo_df = GetBasicStockInfo()
        print(stockId)

        stockInfo_df = basicStockInfo_df[basicStockInfo_df["è­‰åˆ¸ä»£è™Ÿ"] == stockId]
        stockInfo_df.reset_index(drop=True, inplace=True)
        print(stockInfo_df)

        if not stockInfo_df.empty:
            Sleep()
            finDetail_df = GetFinDetail(stockId)
            print(finDetail_df)

            PE_df = GetPE(stockId)
            print(PE_df)

            Sleep()
            transaction_df = GetTransaction(stockId)
            print(transaction_df)

            volume_df = GetVolume(stockId)
            print(volume_df)

            Sleep()
            dividend_df = GetDividend(stockId)
            print(dividend_df)

            Sleep()
            distribution_df = shareholderDistribution.GetDistribution(stockId)
            print(distribution_df)

            # åˆä½µæ‰€æœ‰æ¬„ä½æˆä¸€åˆ—
            temp_df = pd.concat([stockInfo_df, transaction_df, volume_df, PE_df, distribution_df, finDetail_df, dividend_df], axis=1)
            print(temp_df)

            # å°‡åˆ—åˆä½µå…¥dataframe
            # sum_df = pd.concat([sum_df, temp_df], axis=0)

            response = retrieve("å½™æ•´æ¸…å–®", "è­‰åˆ¸ä»£è™Ÿ", stockId)
            records = json.loads(response.text)["records"]
            if len(records) == 0:
                save("å½™æ•´æ¸…å–®", temp_df)
            else:
                updateJsonData = {"records": [{"id": records[0]["id"], "fields": jsonData["records"][0]["fields"]}]}
                print(updateJsonData)
                updateJson("å½™æ•´æ¸…å–®", updateJsonData)

        return {"message": "åŸ·è¡ŒæˆåŠŸ"}

    # æ—¥å¸¸ç±Œç¢¼é¢è³‡æ–™
    if op == 3:
        basicStockInfo_df = GetBasicStockInfo()
        # sum_df = pd.DataFrame()
        for stockId in stocks:
            print(stockId)

            stockInfo_df = basicStockInfo_df[basicStockInfo_df["è­‰åˆ¸ä»£è™Ÿ"] == stockId]
            stockInfo_df.reset_index(drop=True, inplace=True)
            print(stockInfo_df)

            if not stockInfo_df.empty:
                Sleep()
                transaction_df = GetTransaction(stockId)
                print(transaction_df)

                volume_df = GetVolume(stockId)
                print(volume_df)

                temp_df = pd.concat([stockInfo_df, transaction_df, volume_df], axis=1)
                print(temp_df)

                temp_df.to_csv(f"\Data\Daily\ç±Œç¢¼é¢è³‡æ–™.csv", mode="a", header=False, encoding="utf_8_sig")
                # åˆä½µæ‰€æœ‰æ¬„ä½æˆä¸€åˆ—
                # sum_df = pd.concat([sum_df, temp_df], axis=0)

        # å°‡åˆ—åˆä½µå…¥dataframe
        # sum_df.to_csv('ç±Œç¢¼é¢è³‡æ–™.csv',encoding='utf_8_sig')

    # å¤§æˆ¶ã€æœ¬ç›Šæ¯”
    if op == 4:
        shareholderDistribution.WriteData()

        for stockId in stocks:
            print(stockId)

            Sleep()
            distribution_df = shareholderDistribution.GetDistribution(stockId)
            print(distribution_df)

            Sleep()
            PE_df = GetPE(stockId)
            print(PE_df)

            temp_df = pd.concat([PE_df, distribution_df], axis=1)
            print(temp_df)

            temp_df.to_csv(f'\Data\\Weekly\è‚¡æ±åˆ†å¸ƒ_æœ¬ç›Šæ¯”_{date.today().strftime("%Y%m%d")}.csv', mode="a", header=False, encoding="utf_8_sig")

    if op == 5:
        directorSharehold.WriteData()

    if op == 7:
        basicStockInfo_df = GetBasicStockInfo()
        topVolumeStocks = dailyTopVolume.GetTopVolume()[:100]

        for stockId in topVolumeStocks:
            print(stockId)

            stockInfo_df = basicStockInfo_df[basicStockInfo_df["è­‰åˆ¸ä»£è™Ÿ"] == stockId]
            stockInfo_df.reset_index(drop=True, inplace=True)
            print(stockInfo_df)

            if not stockInfo_df.empty:
                volume_df = GetVolume(stockId)
                print(volume_df)

                temp_df = pd.concat([stockInfo_df, volume_df], axis=1)
                print(temp_df)

                temp_df.to_csv(f'\Data\Daily\ç•°å¸¸ç±Œç¢¼è³‡æ–™_{date.today().strftime("%Y%m%d")}.csv', mode="a", header=False, encoding="utf_8_sig")

        # åˆªé™¤æš«å­˜æª”æ¡ˆ
        try:
            folderPath = pathlib.Path(f'\Data\Daily\Chip\{(date.today() - timedelta(days=1)).strftime("%Y%m%d")}')
            delete_folder(folderPath)
        except Exception as ex:
            print(ex)

    if op == 999:
        jsonData = {
            "records": [
                {
                    "fields": {
                        "2018": "  2.58 /    0.0",
                        "2019": "   5.0 /    0.0",
                        "2020": "   6.5 /   0.0",
                        "2021": "   9.0 /    0.0",
                        "2022": " 13.81 /    0.0",
                        "è­‰åˆ¸ä»£è™Ÿ": "2458",
                        "è­‰åˆ¸åç¨±": "ç¾©éš†",
                        "å…¬å¸åç¨±": "ç¾©éš†é›»å­è‚¡ä»½æœ‰é™å…¬å¸",
                        "è³‡æœ¬é¡": 30.38803968,
                        "æˆç«‹æ—¥æœŸ": "19940505",
                        "ä¸Šå¸‚æ—¥æœŸ": "20010917",
                        "æ®–åˆ©ç‡": "12.85",
                        "æœ¬ç›Šæ¯”": "6.37",
                        "æ·¨å€¼æ¯”": "2.66",
                        "æ”¶ç›¤(1ma / 5ma / 20ma / 60ma)": "ğŸ‘   107.5 /    108.3 /   108.55 /   131.06",
                        "å¼µæ•¸(1ma / 5ma / 20ma / 60ma)": "   975.0 /   1167.2 /  1797.75 /  1372.68",
                        "å¤–è³‡æŒè‚¡(%)(1ma / 5ma / 20ma / 60ma)": "    23.5 /    23.38 /    22.86 /     22.0",
                        "åˆ¸è³‡æ¯”(%)(1ma / 5ma / 20ma / 60ma)": "    33.1 /    26.14 /    15.24 /     9.47",
                        "è¶…é¡è²·è¶…": 0.98,
                        "é‡æŠ¼åˆ¸å•†": "",
                        "å‰15å·å•†ç±Œç¢¼é›†ä¸­åº¦": "0.06",
                        "è²·è³£å®¶æ•¸å·®": 78,
                        "æœ¬ç›Šæ¯”-ç´šè·1å€æ•¸": "9",
                        "æœ¬ç›Šæ¯”-ç´šè·1åƒ¹æ ¼": "152.1",
                        "æœ¬ç›Šæ¯”-ç´šè·2å€æ•¸": "11",
                        "æœ¬ç›Šæ¯”-ç´šè·2åƒ¹æ ¼": "185.9",
                        "æœ¬ç›Šæ¯”-ç´šè·3å€æ•¸": "13",
                        "æœ¬ç›Šæ¯”-ç´šè·3åƒ¹æ ¼": "219.7",
                        "æœ¬ç›Šæ¯”-ç´šè·4å€æ•¸": "15",
                        "æœ¬ç›Šæ¯”-ç´šè·4åƒ¹æ ¼": "253.5",
                        "æœ¬ç›Šæ¯”-ç´šè·5å€æ•¸": "17",
                        "æœ¬ç›Šæ¯”-ç´šè·5åƒ¹æ ¼": "287.3",
                        "æœ¬ç›Šæ¯”-ç´šè·6å€æ•¸": "19",
                        "æœ¬ç›Šæ¯”-ç´šè·6åƒ¹æ ¼": "321.1",
                        "100å¼µä»¥ä¸‹æ¯”ä¾‹": "36.17  /  35.72  /  35.5  /  35.8  /  35.44",
                        "100-1000å¼µæ¯”ä¾‹": "16.11  /  16.55  /  16.24  /  16.71  /  17.22",
                        "1000å¼µä»¥ä¸Šæ¯”ä¾‹": "47.66  /  47.63  /  48.17  /  47.61  /  47.25",
                        "1000å¼µä»¥ä¸Šäººæ•¸": "45.0  /  45.0  /  46.0  /  46.0  /  45.0",
                        "æ¯›åˆ©ç‡": "47.24",
                        "ç‡Ÿæ¥­åˆ©ç›Šç‡": "27.15",
                        "ROE": "27.02",
                        "ç¨…å‰æ·¨åˆ©ç‡": "24.72",
                        "ç¨…å¾Œæ·¨åˆ©ç‡": "18.86",
                        "ç¸½è³‡ç”¢é€±è½‰ç‡": "0.93",
                        "æœ¬æ¥­æ”¶ç›Š": "109.83",
                        "æ¯è‚¡ç‡Ÿæ¥­ç¾é‡‘æµé‡": "2.66",
                        "æ¯è‚¡è‡ªç”±ç¾é‡‘æµé‡": "-1.5",
                        "è²¡å ±è©•åˆ†": "68",
                    }
                }
            ]
        }
        response = retrieve("å½™æ•´æ¸…å–®", "è­‰åˆ¸ä»£è™Ÿ", "2458")
        records = json.loads(response.text)["records"]
        print(records)
        if len(records) == 0:
            createJson("å½™æ•´æ¸…å–®", jsonData)
        else:
            newJsonData = {"records": [{"id": records[0]["id"], "fields": jsonData["records"][0]["fields"]}]}
            print(newJsonData)
            updateJson("å½™æ•´æ¸…å–®", newJsonData)


# ------ å…±ç”¨çš„ function ------


def delete_folder(path):
    for sub in path.iterdir():
        if sub.is_dir():
            delete_folder(sub)
        else:
            sub.unlink()
    path.rmdir()


load_dotenv()
BASE_ID = os.environ.get("BASE_ID")
API_KEY = os.environ.get("API_KEY")

# Headers
headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json; charset=utf-8"}
url = f"https://api.airtable.com/v0/{BASE_ID}/"


def createJson(tableName, data):
    response = requests.post(url + tableName, data=json.dumps(data), headers=headers)
    print(response.json())


def updateJson(tableName, data):
    response = requests.patch(url + tableName, data=json.dumps(data), headers=headers)
    print(response.json())


def save(tableName, df):
    # æ¯æ¬¡ä¸Šé™ç‚º10ç­†
    if len(df.index) > 10:
        pageSize = 10
        totalItems = df.shape[0] 
        totalPages = totalItems // pageSize
        startIndex = 0
        endIndex = 0
        print("dataframe page size:" + str(totalPages))
        for pageIndex in range(totalPages + 1):
            print('pageIndex:' + str(pageIndex))
            startIndex = pageSize * pageIndex
            endIndex = pageSize * (pageIndex + 1) - 1
            if endIndex > totalItems:
                endIndex = totalItems
            print("start:" + str(startIndex) + ", end:" + str(endIndex))
            print(df.iloc[startIndex : endIndex])
            jsonData = dataFrame2Json(df.iloc[startIndex : endIndex])
            createJson(tableName, jsonData)
    else:
        jsonData = dataFrame2Json(df)
        createJson(tableName, jsonData)

# åˆªé™¤ä¸Šé™ç‚º10ç­†
def deleteAll(tableName):
    response = getAll(tableName)
    allRecords = json.loads(response.text)
    # print(allRecords)
    deleteParams = ""
    count = 0
    for record in allRecords["records"]:
        deleteParams = deleteParams + ("&" if deleteParams != "" else "") + "records[]=" + record["id"]
        count += 1
        if (count % 10 == 0) or (count == len(allRecords["records"])):
            # print(deleteParams)
            tempUrl = url + tableName + ("?" if deleteParams != "" else "") + deleteParams
            requests.delete(tempUrl, headers=headers)
            deleteParams = ""


def getAll(tableName):
    return requests.get(url + tableName, headers=headers)


def retrieve(tableName, column, value):
    tempUrl = url + tableName + "?filterByFormula={" + column + "}='" + value + "'"
    print(tempUrl)
    return requests.get(tempUrl, headers=headers)


def dataFrame2Json(df):
    """
    æ ¼å¼å¿…é ˆç‚º
    {
        "records" [
            {
                "fields": {
                    "Column1": value
                }
            },
            {
                "fields": {
                    "Column1": value
                }
            },
            ...
        ]
    }
    """
    pd_json = df.to_json(orient="records")
    jsonRecord = json.loads(pd_json)

    fields = []
    for record in jsonRecord:
        for k, v in record.items():
            try:
                # è½‰ç‚ºæ–‡å­—
                if k in (
                    "è­‰åˆ¸ä»£è™Ÿ",
                    "æˆç«‹æ—¥æœŸ",
                    "ä¸Šå¸‚æ—¥æœŸ",
                    "æ”¶ç›¤(1ma / 5ma / 20ma / 60ma)",
                    "å¼µæ•¸(1ma / 5ma / 20ma / 60ma)",
                    "å¤–è³‡æŒè‚¡(%)(1ma / 5ma / 20ma / 60ma)",
                    "åˆ¸è³‡æ¯”(%)(1ma / 5ma / 20ma / 60ma)",
                    "é‡æŠ¼åˆ¸å•†",
                    """
                    "100å¼µä»¥ä¸‹æ¯”ä¾‹",
                    "100-1000å¼µæ¯”ä¾‹",
                    "1000å¼µä»¥ä¸Šæ¯”ä¾‹",
                    "1000å¼µä»¥ä¸Šäººæ•¸",
                    """,
                ):
                    record[k] = str(v)
                else:
                    record[k] = v
            except (ValueError, TypeError):
                pass
        entry = {"fields": record}
        fields.append(entry)

    data = {"records": fields}
    print(data)
    return data


def Sleep():
    time.sleep(random.randint(10, 20))


# ------ æ¸¬è©¦ ------
# 0 ç”¢ç”Ÿéæ¿¾æ¸…å–®(æœ¬ç›Šæ¯”ã€æ®–åˆ©ç‡ã€æ·¨å€¼æ¯”ã€æ”¶ç›¤åƒ¹ã€å…¨é«”è‘£ç›£æŒè‚¡ã€è‚¡æ±åˆ†å¸ƒäººæ•¸)
# 1 ç”¢ç”Ÿéæ¿¾æ¸…å–®(åŒ0å«æœ¬ç›Šæ¯”)
# 2 æŠ“å‡ºè‚¡ç¥¨æ˜ç´°è³‡æ–™
# 3 æ—¥æ’ç¨‹ - ç±Œç¢¼é¢è³‡æ–™
# 4 é€±æ’ç¨‹ - å¤§æˆ¶ã€æœ¬ç›Šæ¯”
# 5 æœˆæ’ç¨‹ - è‘£ç›£æ¯”ä¾‹
# 6 å­£æ’ç¨‹ - è²¡å‹™è³‡æ–™
# 7 æ—¥æ’ç¨‹ - ç•°å¸¸è²·å…¥
# GetChampionStock(0)
